host: sysGen-devCube-0819-8700-01
Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 4
Rules claiming more threads will be scaled down.
Job stats:
job                    count
-------------------  -------
all                        1
dock                       1
extract_grid_center        1
get_grid_center            1
prepare_ligand             1
prepare_protein            1
total                      6

Select jobs to execute...
Execute 2 jobs...

[Thu Sep 12 17:36:10 2024]
localrule prepare_ligand:
    input: data/ligands/E.sdf
    output: output/ligands_prep/E.pdbqt
    jobid: 3
    reason: Missing output files: output/ligands_prep/E.pdbqt
    wildcards: ligand=E
    resources: tmpdir=/tmp


[Thu Sep 12 17:36:10 2024]
localrule prepare_protein:
    input: data/proteins/zAR.pdb
    output: output/proteins_prep/zAR.pdbqt
    jobid: 2
    reason: Missing output files: output/proteins_prep/zAR.pdbqt; Code has changed since last execution
    wildcards: protein=zAR
    resources: tmpdir=/tmp

[Thu Sep 12 17:36:10 2024]
Error in rule prepare_ligand:
    jobid: 3
    input: data/ligands/E.sdf
    output: output/ligands_prep/E.pdbqt
    shell:
        
        prepare_ligand4.py -l data/ligands/E.sdf -o output/ligands_prep/E.pdbqt
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

[Thu Sep 12 17:36:11 2024]
Finished job 2.
1 of 6 steps (17%) done
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake/log/2024-09-12T173610.848416.snakemake.log
WorkflowError:
At least one job did not complete successfully.
